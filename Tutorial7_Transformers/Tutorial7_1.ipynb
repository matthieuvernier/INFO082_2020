{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilización de modelos basados en Transformers\n",
    "\n",
    "\n",
    "La libreria Transformers (https://huggingface.co/transformers) se especializa en ofrecer una API para utilizar y entrenar modelos basados en la arquitectura de red neuronales de tipo **_Transformers_** (https://arxiv.org/abs/1706.03762, 2017). Estos modelos permiten abordar un amplio conjunto de tareas de NLP, dentro de las cuales:\n",
    "\n",
    "\n",
    "- **Question answering** : a partir de una pregunta y un texto, extraer una respuesta del texto\n",
    "\n",
    "\n",
    "- **Sentiment Analysis** : determinar si un texto es positivo o negativo\n",
    "\n",
    "\n",
    "- **Generación de texto** : generar un texto a partir de una secuencia inicial\n",
    "\n",
    "\n",
    "- **Reconocimiento de entidades** (NER): identificar y clasificar secuencias de palabras que representan una entidad (persona, lugar, etc.)\n",
    "\n",
    "\n",
    "- **Resumen automático**: Generar un resumen a partir de un texto largo\n",
    "\n",
    "\n",
    "- **Traducción automática**: Traducir un texto hacia otro idioma\n",
    "\n",
    "\n",
    "- **Completar textos con palabras faltantes**: A partir de un texto dentro del cuál algunas palabras están replazadas por [MASK], proponer palabras para completar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -V\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow\n",
    "#!pip install --user transformers==2.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La libreria está acompañado por un \"hub\" de modelos pre-entrenados, por idioma y por tarea: https://huggingface.co/models\n",
    "\n",
    "La manera más fácil de utilizar un modelo pre-entrenados para abordar tareas NLP consiste en utilizar el método <code>pipeline()</code>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"distilbert-base-cased-distilled-squad\"\n",
    "nlp = pipeline(\"question-answering\", model=model, tokenizer=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Ejemplo básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the examples/question-answering/run_squad.py script.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nlp(question=\"What is question answering?\", context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(result['score'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(result['start']) + \" \" + str(result['end']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ejemplos combinados con Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "wikipedia.set_lang(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_wiki = wikipedia.summary(wikipedia.search(\"Ada Lovelace\")[0], sentences=3)\n",
    "print(context_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = nlp(question=\"Who is Ada Lovelace?\", context=context_wiki)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nlp(question=\"What is the profession of Ada Lovelace?\", context=context_wiki)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nlp(question=\"When does Ada Lovelace born?\", context=context_wiki)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nlp(question=\"What did Ada Lovelace believe?\", context=context_wiki)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_wiki = wikipedia.summary(wikipedia.search(\"Chile\")[0], auto_suggest=False, sentences=4)\n",
    "print(context_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is the capital of Chile?\",\n",
    "    \"How many people live in Chile?\",\n",
    "    \"Where is Chile?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    \n",
    "    result = nlp(question=question, tokenizer=model, model=model, context=context_wiki)\n",
    "    print(question)\n",
    "    print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Ejemplo en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "model=\"mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang(\"es\")\n",
    "\n",
    "context_wiki = wikipedia.summary(wikipedia.search(\"Valdivia\")[0], auto_suggest=False, sentences=4)\n",
    "print(context_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"En qué año fue fundada Valdivia?\",\n",
    "    \"Cuál río pasa por Valdivia?\",\n",
    "    \"Cuántos habitantes viven en Valdivia?\",\n",
    "    \"A qué distancia de Santiago se encuentra Valdivia?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    \n",
    "    result = nlp(question=question, tokenizer=tokenizer, model=model, context=context_wiki)\n",
    "    print(question)\n",
    "    print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Palabra faltante (_fill mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "path=\"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(path)\n",
    "\n",
    "nlp = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "sequence = \"Para solucionar los problemas de Chile, el presidente debe \"\\\n",
    "+ tokenizer.mask_token +\\\n",
    "\" de inmediato.\"\n",
    "\n",
    "result = nlp(sequence)\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generación de textos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_generator(\"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. \", max_length=250, do_sample=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\"text-generation\", model=\"mrm8488/GuaPeTe-2-tiny\", tokenizer=\"mrm8488/GuaPeTe-2-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_generator(\"Desde ayer, el equipo de fútbol de Chile participa a la copa \", max_length=100, do_sample=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resumen automático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang(\"en\")\n",
    "TEXT = wikipedia.summary(wikipedia.search(\"Ada Lovelace\")[0], sentences=10, auto_suggest=False)\n",
    "print(len(TEXT))\n",
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarizer(TEXT, max_length=200, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Traducción automática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation_en_to_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translator(\"Hugging Face is a technology company based in New York and Paris\", max_length=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mosestokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Español -> Inglés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer, MarianTokenizer, MarianMTModel\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-es-en\"\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text=[\"Valdivia es una comuna y ciudad de Chile, capital de la provincia homónima y de la Región de Los Ríos. Se encuentra a 847,6 km al sur de Santiago, la capital de Chile.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = model.generate(**tokenizer.prepare_translation_batch(src_text))\n",
    "tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inglés -> Español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer, MarianTokenizer, MarianMTModel\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text=[\"Valdivia is a municipality and city of Chile, capital of the province of Chile and the Los Ríos Region. It is located 847.6 km south of Santiago, the capital of Chile.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = model.generate(**tokenizer.prepare_translation_batch(src_text))\n",
    "tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "print(tgt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nlp(\"I hate you\")\n",
    "\n",
    "pprint(result)\n",
    "\n",
    "result = nlp(\"I love you\")\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
    "\n",
    "result = nlp(text)\n",
    "\n",
    "pprint(result)\n",
    "\n",
    "text2=\"This is a film which should be seen by anybody interested in, effected by, or suffering from an eating disorder. It is an amazingly accurate and sensitive portrayal of bulimia in a teenage girl, its causes and its symptoms. The girl is played by one of the most brilliant young actresses working in cinema today, Alison Lohman, who was later so spectacular in 'Where the Truth Lies'. I would recommend that this film be shown in all schools, as you will never see a better on this subject. Alison Lohman is absolutely outstanding, and one marvels at her ability to convey the anguish of a girl suffering from this compulsive disorder. If barometers tell us the air pressure, Alison Lohman tells us the emotional pressure with the same degree of accuracy. Her emotional range is so precise, each scene could be measured microscopically for its gradations of trauma, on a scale of rising hysteria and desperation which reaches unbearable intensity. Mare Winningham is the perfect choice to play her mother, and does so with immense sympathy and a range of emotions just as finely tuned as Lohman's. Together, they make a pair of sensitive emotional oscillators vibrating in resonance with one another. This film is really an astonishing achievement, and director Katt Shea should be proud of it. The only reason for not seeing it is if you are not interested in people. But even if you like nature films best, this is after all animal behaviour at the sharp edge. Bulimia is an extreme version of how a tormented soul can destroy her own body in a frenzy of despair. And if we don't sympathise with people suffering from the depths of despair, then we are dead inside.\"\n",
    "\n",
    "result = nlp(text2)\n",
    "\n",
    "pprint(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Esta historia, en conclusión, es una impresionante obra cinematográfica, que solventa la idea de la imperfección de la perfección, y de la utilidad de la memoria, recomendable para aquel que guste de películas abstractas y que buscan expresar una idea sobre cualquier otra cosa.\"\n",
    "\n",
    "result = nlp(text)\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reconocimiento de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"The Trump campaign said Wednesday that it will seek a limited recount of two Wisconsin counties. The campaign needs to officially request the recount, and pay an upfront fee, by 5 p.m. CT Wednesday. Wisconsin election officials confirmed on Wednesday that they received a partial payment of $3 million from the Trump campaign. These officials said last week that the price tag for a statewide recount would be approximately $7.9 million.\"\n",
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(nlp(TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modelos para resolver tareas de NLP basados en redes neuronales Transformers\n",
    "\n",
    "- Todas las tareas anteriores pueden modelarse cómo un problema de \"traducción\":\n",
    "    - **Input**: una secuencia de palabras\n",
    "    - **Ouput**: una secuencia de palabras (eventualmente 1 secuencia de 1 palabra para los problemas de clasificación)\n",
    "    \n",
    "   \n",
    "       \n",
    "- Historicamente, en NLP, los problemas de \"traducción\" de secuencias se abordan con modelos de redes neuronales recurrentes (RNN). En 2017, la arquitectura _Transformers_ mejora las arquitecturas RNN integrando un mecanismo de \"atención\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"architecture.png\" />\n",
    "\n",
    "\n",
    "### - Artículo: \"Attention is all you need\" (2017) : https://arxiv.org/abs/1706.03762\n",
    "\n",
    "### - Charla Jorge Pérez (DCC - Universidad de Chile, septiembre 2020): https://www.youtube.com/watch?v=4cY1H-QVlZM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
